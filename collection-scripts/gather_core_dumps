#!/bin/bash
BASE_COLLECTION_PATH="must-gather"
CORE_DUMP_PATH=${OUT:-"${BASE_COLLECTION_PATH}/node_core_dumps"}

mkdir -p "${CORE_DUMP_PATH}"/

function get_dump_off_node {
    local debugPod=""

    #Start Debug pod in background and capture output to get pod name
    local tmpfile=$(mktemp)
    oc debug --to-namespace="default" node/"$1" -- /bin/bash -c 'sleep 300' > "$tmpfile" 2>&1 &

    #Wait for the debug pod to be created and extract its name with exponential backoff
    local max_attempts=10  # Fewer attempts needed with exponential backoff
    local attempt=0
    local base_delay=0.1  # Starting delay in seconds
    local max_delay=2.0   # Cap the maximum delay

    # Initial delay to allow pod creation to start
    sleep 0.5

    while [ -z "$debugPod" ] && [ $attempt -lt $max_attempts ]; do
        debugPod=$(sed -n 's/.*pod\/\([^ ]*\).*/\1/p' "$tmpfile" 2>/dev/null | head -1)
        if [ -z "$debugPod" ]; then
            # Calculate exponential backoff: base_delay * 2^attempt
            local delay=$(awk -v base="$base_delay" -v exponent="$attempt" -v max="$max_delay" \
                'BEGIN {d = base * (2 ^ exponent); print (d > max) ? max : d}')
            sleep "$delay"
            attempt=$((attempt + 1))
        fi
    done
    rm -f "$tmpfile"

    #Wait for pod to be ready
    if [ -n "$debugPod" ]; then
      oc wait -n "default" --for=condition=Ready pod/"$debugPod" --timeout=30s > /dev/null 2>&1
    fi

    if [ -z "$debugPod" ]
    then
      echo "Debug pod for node ""$1"" never activated"
    else
      #Copy Core Dumps out of Nodes suppress Stdout
      echo "Copying core dumps on node ""$1"""
      if ! oc cp  --loglevel 1 -n "default" "$debugPod":/host/var/lib/systemd/coredump "${CORE_DUMP_PATH}"/"$1"_core_dump > /dev/null 2>&1; then
        echo "Warning: Failed to copy core dumps from node $1"
      fi

      #clean up debug pod after we are done using them
      oc delete pod "$debugPod" -n "default"
    fi
}

function gather_core_dump_data {
  #Run coredump pull function on all nodes in parallel
  for NODE in ${NODES}; do
    get_dump_off_node "${NODE}" &
    PIDS+=($!)
  done
}

if [ $# -eq 0 ]; then
    echo "WARNING: Collecting core dumps on ALL linux nodes in your cluster. This could take a long time."
fi

PIDS=()
NODES="${*:-$(oc get nodes -o jsonpath='{.items[?(@.status.nodeInfo.operatingSystem=="linux")].metadata.name}')}"

gather_core_dump_data

echo "INFO: Waiting for node core dump collection to complete ..."
wait "${PIDS[@]}"
echo "INFO: Node core dump collection to complete."

# force disk flush to ensure that all data gathered is accessible in the copy container
sync

